{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Profitable App Profiles for the App Store and Google Play Markets__\n",
    "\n",
    "This Project simulates real world scenario of __data analysis__ of __Android__ and __iOS__ mobile apps.\n",
    "\n",
    "__Aim__ of this project is to find _mobile app profiles_ for the App Store and Google Play markets. The project simulates a __data analyst's__ task in a company that builds Android and iOS mobile apps, that enables team of __developers__ to make data_driven decisions with respect to the kind of apps they build.\n",
    "\n",
    "Presumably the company, builds apps that are free to download and install, and main source of revenue consists of in-app ads. This means that revenue for any given app is mostly influenced by the __number of users__ that use the app.\n",
    "__Goal__ for this project is to analyze data to help developers understand what kind of apps are likely to attract more users.\n",
    "\n",
    "Starting initially by opening the two data sets and then continue with exploring data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "\n",
    "### The Google Play data set ###\n",
    "opened_file=open('googleplaystore.csv')\n",
    "read_file=reader(opened_file)\n",
    "android=list(read_file)\n",
    "android_header=android[0]\n",
    "android=android[1:]\n",
    "\n",
    "### The App Store data set ###\n",
    "opened_file=open('AppleStore.csv')\n",
    "read_file=reader(opened_file)\n",
    "ios=list(read_file)\n",
    "ios_header=ios[0]\n",
    "ios=ios[1:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a function named __explore_data()__, this function will be repeatedly invoked to explore rows in a more redable way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## android dataset header: \n",
      "\n",
      "\n",
      "['App', 'Category', 'Rating', 'Reviews', 'Size', 'Installs', 'Type', 'Price', 'Content Rating', 'Genres', 'Last Updated', 'Current Ver', 'Android Ver']\n",
      "\n",
      "\n",
      "## android dataset first two rows\n",
      "\n",
      "\n",
      "row : 1\n",
      "['Photo Editor & Candy Camera & Grid & ScrapBook', 'ART_AND_DESIGN', '4.1', '159', '19M', '10,000+', 'Free', '0', 'Everyone', 'Art & Design', 'January 7, 2018', '1.0.0', '4.0.3 and up']\n",
      "\n",
      "\n",
      "row : 2\n",
      "['Coloring book moana', 'ART_AND_DESIGN', '3.9', '967', '14M', '500,000+', 'Free', '0', 'Everyone', 'Art & Design;Pretend Play', 'January 15, 2018', '2.0.0', '4.0.3 and up']\n",
      "\n",
      "\n",
      "Number of rows: 10841\n",
      "Number of columns: 13\n",
      "None\n",
      "\n",
      "\n",
      "## iOS appstore dataset header\n",
      "\n",
      "\n",
      "['id', 'track_name', 'size_bytes', 'currency', 'price', 'rating_count_tot', 'rating_count_ver', 'user_rating', 'user_rating_ver', 'ver', 'cont_rating', 'prime_genre', 'sup_devices.num', 'ipadSc_urls.num', 'lang.num', 'vpp_lic']\n",
      "\n",
      "\n",
      "## iOS dataset first row\n",
      "\n",
      "\n",
      "row : 1\n",
      "['284882215', 'Facebook', '389879808', 'USD', '0.0', '2974676', '212', '3.5', '3.5', '95.0', '4+', 'Social Networking', '37', '1', '29', '1']\n",
      "\n",
      "\n",
      "Number of rows: 7197\n",
      "Number of columns: 16\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def explore_data(dataset, start, end, rows_and_columns=False):\n",
    "    dataset_slice=dataset[start:end]\n",
    "    count=start\n",
    "    for row in dataset_slice:\n",
    "        count+=1\n",
    "        print('row : ' + str(count))\n",
    "        print(row)\n",
    "        print('\\n')\n",
    "    if rows_and_columns:\n",
    "        print('Number of rows:', len(dataset))\n",
    "        print('Number of columns:', len(dataset[0]))\n",
    "\n",
    "\n",
    "print('## android dataset header: ')\n",
    "print('\\n')\n",
    "print(android_header)\n",
    "print('\\n')\n",
    "print('## android dataset first two rows')\n",
    "print('\\n')\n",
    "print(explore_data(android, 0, 2, True))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print('## iOS appstore dataset header')\n",
    "print('\\n')\n",
    "print(ios_header)\n",
    "print('\\n')\n",
    "print('## iOS dataset first row')\n",
    "print('\\n')\n",
    "print(explore_data(ios, 0, 1, True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__googleplaystore__ dataset documentation : https://www.kaggle.com/lava18/google-play-store-apps<br/>\n",
    "__applestore__ dataset documentation : https://www.kaggle.com/ramamet4/app-store-apple-data-set-10k-apps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Deleting wrong data__\n",
    "\n",
    "Previously, I have opened the datasets and explored the data. Before analysis, it should be made sure that the data is __accurate__, or the results of the analysis might be __wrong__. To ensure such the follwing need to be done:\n",
    "\n",
    "1. Detect inaccurate data, and correct or remove it.\n",
    "2. Detect duplicate data, and remove duplicates. \n",
    "\n",
    "As this project focuses on apps that are free to install and download, and for English-speaking audience.\n",
    "\n",
    "1. Filter apps that are not in English language.\n",
    "2. Filter apps that are not free.\n",
    "\n",
    "The above mentioned process of data preparation is called __data cleaning__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The discussions section has a mention that rating at entry 10473 is wrong.\n",
    "    I will try to print the row at that index to check if it's incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['App', 'Category', 'Rating', 'Reviews', 'Size', 'Installs', 'Type', 'Price', 'Content Rating', 'Genres', 'Last Updated', 'Current Ver', 'Android Ver']\n",
      "row : 10472\n",
      "['Xposed Wi-Fi-Pwd', 'PERSONALIZATION', '3.5', '1042', '404k', '100,000+', 'Free', '0', 'Everyone', 'Personalization', 'August 5, 2014', '3.0.0', '4.0.3 and up']\n",
      "\n",
      "\n",
      "row : 10473\n",
      "['Life Made WI-Fi Touchscreen Photo Frame', '1.9', '19', '3.0M', '1,000+', 'Free', '0', 'Everyone', '', 'February 11, 2018', '1.0.19', '4.0 and up']\n",
      "\n",
      "\n",
      "Number of rows: 10841\n",
      "Number of columns: 13\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(android_header)\n",
    "print(explore_data(android, 10471, 10473, True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As evident from the above function return that the row has errors in the __Category__ column.\n",
    "I will delete the error row to clean the dataset of errors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row : 10472\n",
      "['Xposed Wi-Fi-Pwd', 'PERSONALIZATION', '3.5', '1042', '404k', '100,000+', 'Free', '0', 'Everyone', 'Personalization', 'August 5, 2014', '3.0.0', '4.0.3 and up']\n",
      "\n",
      "\n",
      "row : 10473\n",
      "['osmino Wi-Fi: free WiFi', 'TOOLS', '4.2', '134203', '4.1M', '10,000,000+', 'Free', '0', 'Everyone', 'Tools', 'August 7, 2018', '6.06.14', '4.4 and up']\n",
      "\n",
      "\n",
      "row : 10474\n",
      "['Sat-Fi Voice', 'COMMUNICATION', '3.4', '37', '14M', '1,000+', 'Free', '0', 'Everyone', 'Communication', 'November 21, 2014', '2.2.1.5', '2.2 and up']\n",
      "\n",
      "\n",
      "Number of rows: 10840\n",
      "Number of columns: 13\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "del android[10472] # deleting the incorrect row\n",
    "print(explore_data(android, 10471, 10474, True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Removing duplicate entries__\n",
    "\n",
    "The discussuns sections of the dataset has mentions about redundant entries. For instance, instagram has four entries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Instagram', 'SOCIAL', '4.5', '66577313', 'Varies with device', '1,000,000,000+', 'Free', '0', 'Teen', 'Social', 'July 31, 2018', 'Varies with device', 'Varies with device']\n",
      "['Instagram', 'SOCIAL', '4.5', '66577446', 'Varies with device', '1,000,000,000+', 'Free', '0', 'Teen', 'Social', 'July 31, 2018', 'Varies with device', 'Varies with device']\n",
      "['Instagram', 'SOCIAL', '4.5', '66577313', 'Varies with device', '1,000,000,000+', 'Free', '0', 'Teen', 'Social', 'July 31, 2018', 'Varies with device', 'Varies with device']\n",
      "['Instagram', 'SOCIAL', '4.5', '66509917', 'Varies with device', '1,000,000,000+', 'Free', '0', 'Teen', 'Social', 'July 31, 2018', 'Varies with device', 'Varies with device']\n"
     ]
    }
   ],
   "source": [
    "for row in android[1:]:\n",
    "    name=row[0]\n",
    "    if name=='Instagram':\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate apps:  1181\n",
      "Names of duplicate apps ['Quick PDF Scanner + OCR FREE', 'Box', 'Google My Business', 'ZOOM Cloud Meetings', 'join.me - Simple Meetings']\n",
      "\n",
      "\n",
      "Number of unique apps:  9659\n"
     ]
    }
   ],
   "source": [
    "# Segregating the duplicate apps and printing names of some duplicate apps\n",
    "\n",
    "duplicate_apps=[]\n",
    "unique_apps=[]\n",
    "for app in android:\n",
    "    name=app[0]\n",
    "    if name in unique_apps:\n",
    "        duplicate_apps.append(name)\n",
    "    else:\n",
    "        unique_apps.append(name)\n",
    "\n",
    "print('Number of duplicate apps: ', len(duplicate_apps))\n",
    "print('Names of duplicate apps', duplicate_apps[:5])\n",
    "print('\\n')\n",
    "print('Number of unique apps: ', len(unique_apps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Removing the duplicate rows__\n",
    "\n",
    "Above I have iterated through the _Google play_ store data set and identified the duplicate or redundant apps.<br />\n",
    "Going forward I need to find a way to permanently remove these duplicate rows based on some criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "google play store dataset header: \n",
      "['App', 'Category', 'Rating', 'Reviews', 'Size', 'Installs', 'Type', 'Price', 'Content Rating', 'Genres', 'Last Updated', 'Current Ver', 'Android Ver']\n",
      "\n",
      "\n",
      "['Instagram', 'SOCIAL', '4.5', '66577313', 'Varies with device', '1,000,000,000+', 'Free', '0', 'Teen', 'Social', 'July 31, 2018', 'Varies with device', 'Varies with device']\n",
      "['Instagram', 'SOCIAL', '4.5', '66577446', 'Varies with device', '1,000,000,000+', 'Free', '0', 'Teen', 'Social', 'July 31, 2018', 'Varies with device', 'Varies with device']\n",
      "['Instagram', 'SOCIAL', '4.5', '66577313', 'Varies with device', '1,000,000,000+', 'Free', '0', 'Teen', 'Social', 'July 31, 2018', 'Varies with device', 'Varies with device']\n",
      "['Instagram', 'SOCIAL', '4.5', '66509917', 'Varies with device', '1,000,000,000+', 'Free', '0', 'Teen', 'Social', 'July 31, 2018', 'Varies with device', 'Varies with device']\n"
     ]
    }
   ],
   "source": [
    "# Examining instagram data to identify a condition based on which duplicate rows can be removed\n",
    "\n",
    "print('google play store dataset header: ')\n",
    "print(android_header)\n",
    "print('\\n')\n",
    "for row in android:\n",
    "    name='Instagram'\n",
    "    if name in row:\n",
    "        print(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above result, we may notice that there is no diffrence in the _data points_ of the Instagram rows based on which I might delete the redundant rows except, __Reviews__ column. The count in the __Reviews__ column increases as more redundant rows are added. I can try to remove all the redundant rows except the one that has maximum reviews, as presumably that might be the most recent one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9659\n"
     ]
    }
   ],
   "source": [
    "# Removing duplicate rows\n",
    "\n",
    "reviews_max={}\n",
    "\n",
    "for row in android:\n",
    "    name=row[0]\n",
    "    n_reviews=float(row[3])\n",
    "    \n",
    "    if name in reviews_max and reviews_max[name]<n_reviews:\n",
    "        reviews_max[name]=n_reviews\n",
    "    elif name not in reviews_max:\n",
    "        reviews_max[name]=n_reviews\n",
    "        \n",
    "#print(reviews_max)\n",
    "print(len(reviews_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9659\n"
     ]
    }
   ],
   "source": [
    " # using review_max to remove duplicate rows\n",
    "    \n",
    "android_clean=[]\n",
    "already_added=[]\n",
    "\n",
    "for row in android:\n",
    "    name=row[0]\n",
    "    n_reviews=float(row[3])\n",
    "    \n",
    "    #1 Checking whether number of reviews of a app(row) in google playstore dataset\n",
    "    # match with number of reviews present as value against a key of same name in \n",
    "    # review_max dictionary and if name not in already_added list, appending that\n",
    "    # row as list in android_clean list.\n",
    "    \n",
    "    #2 Appending the name of the app in already_added list to keep track of the\n",
    "    # apps already added\n",
    "    \n",
    "    if (reviews_max[name]==n_reviews) and (name not in already_added):\n",
    "        android_clean.append(row)  #1\n",
    "        already_added.append(name) #2\n",
    "\n",
    "# Exploring android_clean length implies that there are 9659 unique rows\n",
    "print(len(android_clean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned earlier this Project aims to derive results from the apps that are for English speaking audience.<br />\n",
    "Which means that all the data of the data set that are for a non English speaking audience needs to be cleaned.<br />\n",
    "Each english characters has a number mapped to it as per ASCII system that ranges from 0-127. <br />\n",
    "I will try and define a function that will iterate over the character of a string and will try to distinguish base on the above mentioned condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D 68\n",
      "o 111\n",
      "c 99\n",
      "s 115\n",
      "  32\n",
      "T 84\n",
      "o 111\n",
      "  32\n",
      "G 71\n",
      "o 111\n",
      "‚Ñ¢ 8482\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_string(string):\n",
    "    for character in string:\n",
    "        ascii_val=ord(character)\n",
    "        print(character, ascii_val)\n",
    "        if ascii_val>127:\n",
    "            return False\n",
    "    return True\n",
    "        \n",
    "# Test test_string() function\n",
    "\n",
    "#test_string('Instagram')\n",
    "#test_string('Áà±Â•áËâ∫PPS -„ÄäÊ¨¢‰πêÈ¢Ç2„ÄãÁîµËßÜÂâßÁÉ≠Êí≠')\n",
    "test_string('Docs To Go‚Ñ¢ Free Office Suite')\n",
    "#test_string('Instachat üòú')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The _test_string()_ function gives correct result on almost all occasions except when there is a _imoji_ in the\n",
    "name of the app. This indicates that the apps that contains _imojis_ but are still for an English speaking audience will be filtered out, which is not desired.<br />\n",
    "To overcome this problem I will modify the _test_string()_ function in a way that it will only filter those strings which have __more than three__ chracters that exceed the ASCII range(0-127) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_string(string):\n",
    "    ascii_exceed=0;\n",
    "    for character in string:\n",
    "        ascii_val=ord(character)\n",
    "        if ascii_val>127:\n",
    "            ascii_exceed+=1\n",
    "    if ascii_exceed>3:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "    \n",
    "#test_string('Docs To Go‚Ñ¢ Free Office Suite')\n",
    "#test_string('Instachat üòú')\n",
    "test_string('Áà±Â•áËâ∫PPS -„ÄäÊ¨¢‰πêÈ¢Ç2„ÄãÁîµËßÜÂâßÁÉ≠Êí≠')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the _test_string()_ function is defined so that it will only filter out those strings that have more than three _imojis_<br />\n",
    "I will use _test_string()_ function to filter out non-English apps from both the datasets. Loop through each dataset. If an app name is identified as English, append the whole row to a separate list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "google playstore dataset:  10840\n",
      "playstore dataset without duplicates:  9659\n",
      "playstore dataset English apps:  9614\n",
      "ios dataset English apps  7197\n"
     ]
    }
   ],
   "source": [
    "playstore_cleaned=[]\n",
    "ios_cleaned=[]\n",
    "\n",
    "for row in android_clean:\n",
    "    name=row[0]\n",
    "    if test_string(name):\n",
    "        playstore_cleaned.append(row)\n",
    "        \n",
    "for row in ios:\n",
    "    name=row[0]\n",
    "    if test_string(name):\n",
    "        ios_cleaned.append(row)\n",
    "\n",
    "# Initial playstore dataset\n",
    "print('google playstore dataset: ', len(android))\n",
    "\n",
    "# playstore dataset after cleaning duplicate rows\n",
    "print('playstore dataset without duplicates: ', len(android_clean))\n",
    "\n",
    "#playstore dataset after removing non-English apps\n",
    "print('playstore dataset English apps: ', len(playstore_cleaned))\n",
    "\n",
    "# ios dataset after removing non-English apps\n",
    "print('ios dataset English apps ', len(ios_cleaned))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be noted that out of 10840 rows 9614 rows are obtained after cleaning the playstore dataset.\n",
    "\n",
    "This project aims to analyze a dataset that contains apps that are free to download and install, implies that\n",
    "the dataset should be isolated from non-free apps, which will be the last step in the __data cleaning__ process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "playstore_final:  no non-free apps\n",
      "ios_final:  no non-free apps\n"
     ]
    }
   ],
   "source": [
    "playstore_final=[]\n",
    "ios_final=[]\n",
    "\n",
    "for row in playstore_cleaned:\n",
    "    price=row[7]\n",
    "    if price=='0':\n",
    "        playstore_final.append(row)\n",
    "        \n",
    "for row in ios_cleaned:\n",
    "    price=row[4]\n",
    "    if price=='0.0':\n",
    "        ios_final.append(row)\n",
    "        \n",
    "        ## CHECKING IF FINAL DATASET(iOS and Google playstore) has a non-free app ##\n",
    "        \n",
    "# Checking if playstore final dataset has non free apps\n",
    "for row in playstore_final:\n",
    "    price=row[7]\n",
    "    if price!='0':\n",
    "        print('non free app')\n",
    "print('playstore_final: ', 'no non-free apps')\n",
    "\n",
    "# Checking if ios final dataset has non free apps\n",
    "for row in ios_final:\n",
    "    price=row[4]\n",
    "    if price!='0.0':\n",
    "        print('non free app')\n",
    "print('ios_final: ', 'no non-free apps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The playstore and ios datasets are now cleaned and ready for __Analysis__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most Common Apps By Genre : \n",
    "\n",
    "Part One:\n",
    "\n",
    "So far I have completed the following steps to clean the data:\n",
    "    \n",
    "    -> Removing inaccurate data\n",
    "    -> Removing duplicate app entries\n",
    "    -> Removing non-english apps\n",
    "    -> Isolating the free apps\n",
    "    \n",
    "    \n",
    "My goal is to determine thw kind of apps that are likely to attract more users because  the number of people using my app\n",
    "affects our revinue.\n",
    "\n",
    "To minimise the risks and overhead, validation strategy for an app idea has three steps:\n",
    "\n",
    "    1. Build a minimal Android version of the app, and add it to Google play.\n",
    "    \n",
    "    2. If  the App has good response from the users, we develop it further.\n",
    "    \n",
    "    3. If the App is profitable after six months, we build an iOS version of the app and add it\n",
    "        to the App Store.\n",
    "        \n",
    "My Goal is to add the app both on Google play and App Store, due to which I need to find App Profiles that are\n",
    "Successful in both markets. For instance, a profile that works well for both markets might be a productivity app\n",
    "that makes use of gamification.\n",
    "\n",
    "I will begin analysis of the most common genres in each market. For this I will build frequency tables for the prime_genre column of the App Store data set, and the Genres and Category columns of the Google play data set.\n",
    "\n",
    "Part Two:\n",
    "\n",
    "1. I will define a function that takes the dataset as parameter \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_table(dataset, index):\n",
    "    table = {}\n",
    "    total = 0 \n",
    "    for row in dataset:\n",
    "        total += 1\n",
    "        value = row[index]\n",
    "        if value in table:\n",
    "            table[value] += 1\n",
    "        else:\n",
    "            table[value] = 1\n",
    "            \n",
    "    table_percentages = {}\n",
    "    for key in table:\n",
    "        percentage = (table[key] / total) * 100\n",
    "        table_percentages[key] = percentage\n",
    "        \n",
    "    return table_percentages\n",
    "\n",
    "def display_table(dataset, index):\n",
    "    table = freq_table(dataset, index)\n",
    "    table_display = []\n",
    "    for key in table:\n",
    "        key_val_as_tuple = (table[key], key)\n",
    "        table_display.append(key_val_as_tuple)\n",
    "        \n",
    "    table_sorted = sorted(table_display, reverse = True)\n",
    "    for entry in table_sorted:\n",
    "        print(entry[1], ':', entry[0])\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part Three:\n",
    "\n",
    "I will start by examining the frequency table for the prime_genre column of the App Store data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Games : 55.64595660749507\n",
      "Entertainment : 8.234714003944774\n",
      "Photo & Video : 4.117357001972387\n",
      "Social Networking : 3.5256410256410255\n",
      "Education : 3.2544378698224854\n",
      "Shopping : 2.983234714003945\n",
      "Utilities : 2.687376725838264\n",
      "Lifestyle : 2.3175542406311638\n",
      "Finance : 2.0710059171597637\n",
      "Sports : 1.947731755424063\n",
      "Health & Fitness : 1.8737672583826428\n",
      "Music : 1.6518737672583828\n",
      "Book : 1.6272189349112427\n",
      "Productivity : 1.5285996055226825\n",
      "News : 1.4299802761341223\n",
      "Travel : 1.3806706114398422\n",
      "Food & Drink : 1.0601577909270217\n",
      "Weather : 0.7642998027613412\n",
      "Reference : 0.4930966469428008\n",
      "Navigation : 0.4930966469428008\n",
      "Business : 0.4930966469428008\n",
      "Catalogs : 0.22189349112426035\n",
      "Medical : 0.19723865877712032\n"
     ]
    }
   ],
   "source": [
    "display_table(ios_final, -5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
